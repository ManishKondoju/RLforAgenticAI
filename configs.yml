random_seed: 42

stream:
  n_items_train: 8000
  n_items_val: 1000
  n_items_test: 1000

calendar:
  work_start: "09:00"
  work_end: "18:00"
  slot_minutes: 30

bandit:
  algo: linucb
  alpha: 0.8
  arms: ["RuleSummarizer", "LLMSummarizer", "HeuristicPriority", "MLPriority", "Skip"]
  context_dim: 10

training:
  epochs: 1
  batches: 1
  results_csv: "plots/bandit_training.csv"

dqn:
  episodes: 300
  steps_per_episode: 200
  gamma: 0.99
  lr: 0.001
  batch_size: 128
  buffer_size: 50000
  start_training_after: 1000
  target_update_every: 500
  eps_start: 1.0
  eps_end: 0.05
  eps_decay: 0.995
  model_path: "models/controller_dqn.pt"
  resume_if_exists: true

ppo:
  total_timesteps: 150000
  slots_per_day: 18
  tasks_per_day: 256   # bigger internal day so PPO won’t “run out”
  slot_minutes: 30
  model_path: "models/scheduler_ppo"
